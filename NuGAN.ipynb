{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NuGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN+w9qY3H4QukHgmj8/4OT+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Olivia-Feldman/NUGAN-DISTGAN/blob/Andrew/NuGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8isMKhlx0xr"
      },
      "source": [
        "# Set up the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk03kg9rxO4W"
      },
      "source": [
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg5lYCj_yCje"
      },
      "source": [
        "# Download the MNIST dataset\n",
        "\n",
        "[MNIST PyTorch Docs](https://pytorch.org/vision/stable/datasets.html#mnist)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ43QkgQyIkV"
      },
      "source": [
        "# MNIST Dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5), std=(0.5))])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_BZppFLyWBC"
      },
      "source": [
        "# Showing shape of train and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPO3ZvOPybpd",
        "outputId": "e5a6cc69-fc1d-42ef-accd-9f89690335b3"
      },
      "source": [
        "print(\"Train Shape:\", train_dataset.data.shape, \"Test Shape:\", test_dataset.data.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Shape: torch.Size([60000, 28, 28]) Test Shape: torch.Size([10000, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ_WamIMwfXI"
      },
      "source": [
        "# Define a function to initialize the weights of the network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_qbzeYmwdCE"
      },
      "source": [
        "def initialize_weights(net):\n",
        "    for m in net.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            m.weight.data.normal_(0, 0.02)\n",
        "            m.bias.data.zero_()\n",
        "        elif isinstance(m, nn.ConvTranspose2d):\n",
        "            m.weight.data.normal_(0, 0.02)\n",
        "            m.bias.data.zero_()\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            m.weight.data.normal_(0, 0.02)\n",
        "            m.bias.data.zero_()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zsrvh6Ruw3L9"
      },
      "source": [
        "def visualize_results(gan):\n",
        "      sample_z_ = torch.rand((10, gan.z_dim)).cuda()\n",
        "      samples = gan.G(sample_z_)\n",
        "      samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n",
        "      samples = (samples + 1) / 2\n",
        "      plt.figure(figsize=((1,10)))\n",
        "      fig,ax = plt.subplots(1,10)\n",
        "      for i in range(10):\n",
        "          s=ax[i].imshow(np.squeeze(samples[i,]))\n",
        "          s=ax[i].get_xaxis().set_visible(False)\n",
        "          s=ax[i].get_yaxis().set_visible(False)\n",
        "      s=plt.show()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DEvIxxCsmBS"
      },
      "source": [
        "from scipy.sparse import linalg\n",
        "\n",
        "def get_eigenvectors(model, dataloader):\n",
        "    # Adds up the number of weights in the model\n",
        "    num_params = sum(p.numel() for p in model.parameters())\n",
        "    print(num_params)\n",
        "    hv = HessianVector(model=model, dataloader=dataloader)\n",
        "\n",
        "    #A = linalg.LinearOperator(shape=(num_params, num_params), matvec=lambda v: hv.calculate(v))\n",
        "    A = linalg.LinearOperator((num_params,num_params), matvec=lambda v: hv.calculate(torch.tensor(v).float()))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tptp9JXltklf"
      },
      "source": [
        "# Hessian Vector Class\n",
        "\n",
        "\n",
        "\n",
        "*   scipy.sparse.linalg.LinearOperator\n",
        "  *   [Docs](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S6BZlQHtkJP"
      },
      "source": [
        "class HessianVector():\n",
        "\n",
        "    def __init__(self, model, dataloader, percentage=0.2):\n",
        "        self.size = int(sum(param.numel() for param in model.parameters()))\n",
        "        self.percentage = percentage\n",
        "        self.dataloader = dataloader\n",
        "        self.model = model\n",
        "\n",
        "\n",
        "    def calculate(self, vector):\n",
        "        print(\"Hessian vector shape:\", vector.shape)\n",
        "\n",
        "        full_hessian = None\n",
        "\n",
        "        vector = vector.cuda()\n",
        "\n",
        "        grad_vec = None\n",
        "        self.dataloader_iter = iter(self.dataloader)\n",
        "        # Number of Batchs = 60000/ 300 (batch_size) = 200\n",
        "        n = int(np.ceil(len(self.dataloader)*self.percentage)) # 200 * 0.2 = 40\n",
        "\n",
        "        print(\"n:\", n)\n",
        "\n",
        "        batch_grad = self.prepare_grad()\n",
        "\n",
        "    def prepare_grad(self):\n",
        "\n",
        "        all_inputs, all_targets = next(self.dataloader_iter)\n",
        "\n",
        "        num_chunks = 1\n",
        "        grad_vec = None\n",
        "\n",
        "        input = all_inputs.cuda()\n",
        "        target = all_targets.cuda()\n",
        "\n",
        "        print(\"input:\", input.shape)\n",
        "        print(\"target:\", input.shape)\n",
        "\n",
        "        output = self.model(input)\n",
        "\n",
        "        print(\"output:\", output.shape)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_jzg_VB0VHj"
      },
      "source": [
        "# Generator and Discriminator class definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAhXVtAo0USV"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim=100, output_dim=1, input_size=32, base_size=64):\n",
        "        super(Generator, self).__init__()  \n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.input_size = 28\n",
        "        self.base_size = base_size    \n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(self.input_dim, self.base_size)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, self.output_dim * self.input_size * self.input_size)\n",
        "\n",
        "        initialize_weights(self)\n",
        "    \n",
        "    # forward method\n",
        "    def forward(self, x): \n",
        "\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        x = torch.tanh(self.fc4(x))\n",
        "        x = x.view(-1, self.output_dim, self.input_size, self.input_size)\n",
        "        return x\n",
        "    \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim=1, output_dim=1, input_size=32, base_size=64):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.input_size = input_size\n",
        "        self.base_size = base_size\n",
        "\n",
        "        self.fc1 = nn.Linear(self.input_size * self.input_size, self.base_size)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, self.output_dim)\n",
        "\n",
        "        initialize_weights(self)\n",
        "    \n",
        "    # forward method\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.view(-1, self.input_size * self.input_size)\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        return torch.sigmoid(self.fc4(x))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PgTyYPe0qhu"
      },
      "source": [
        "# Construction of GAN model\n",
        "\n",
        "[Modifying gradients in PyTorch](https://discuss.pytorch.org/t/how-to-modify-the-gradient-manually/7483)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUZu_Ztd0uD3"
      },
      "source": [
        "class GAN():\n",
        "    def __init__(self,params):\n",
        "        # parameters\n",
        "        self.epoch = params['max_epochs']\n",
        "        self.sample_num = 100\n",
        "        self.batch_size = 300\n",
        "        self.input_size = 28\n",
        "        self.z_dim = params['z_dim']\n",
        "        self.base_size = params['base_size']\n",
        "\n",
        "        # load dataset\n",
        "        self.data_loader = torch.utils.data.DataLoader(train_dataset, \n",
        "                                               batch_size=self.batch_size, \n",
        "                                               shuffle=True)\n",
        "        self.test_loader = torch.utils.data.DataLoader(test_dataset, \n",
        "                                               batch_size=self.batch_size, \n",
        "                                               shuffle=True)\n",
        "        data = self.data_loader.__iter__().__next__()[0]\n",
        "\n",
        "        #mnist_dim = data.shape[1] * data.shape[2]\n",
        "\n",
        "        #print(data.shape)\n",
        "        #self.data_width = data.shape[2]\n",
        "        #self.data_height = data.shape[3]\n",
        "\n",
        "        # initialization of the generator and discriminator\n",
        "        self.G = Generator(\n",
        "            input_dim=self.z_dim, \n",
        "            output_dim=data.shape[1],\n",
        "            input_size=self.input_size, \n",
        "            base_size=self.base_size\n",
        "            ).cuda()\n",
        "\n",
        "        self.D = Discriminator(\n",
        "            input_dim=data.shape[1], \n",
        "            output_dim=1,\n",
        "            input_size=self.input_size, \n",
        "            base_size=self.base_size\n",
        "            ).cuda()\n",
        "\n",
        "        #print(\"Encoder\", data.shape[1], self.input_size, self.base_size)\n",
        "        #self.E = encoder(input_dim=data.shape[1], output_dim=self.z_dim, input_size=self.input_size, base_size=self.base_size).cuda()\n",
        "        #self.G_optimizer = optim.SGD(self.G.parameters(), lr=params['lr_g'])\n",
        "        #self.D_optimizer = optim.SGD(self.D.parameters(), lr=params['lr_d'])\n",
        "        self.G_optimizer = optim.Adam(self.G.parameters(), lr=params['lr_g'], betas=(params['beta1'], params['beta2']))\n",
        "        self.D_optimizer = optim.Adam(self.D.parameters(), lr=params['lr_d'], betas=(params['beta1'], params['beta2']))\n",
        "        #self.E_optimizer = optim.Adam(self.E.parameters(), lr=1e-2, weight_decay=1e-4)\n",
        "        \n",
        "        # initialization of the loss function\n",
        "\n",
        "        self.BCE_loss = nn.BCELoss().cuda()\n",
        "        #self.smooth_loss = nn.SmoothL1Loss().cuda()\n",
        "        \n",
        "        # Gettng a batch of noise to generate the fake data\n",
        "        self.sample_z_ = torch.rand((self.batch_size, self.z_dim)).cuda()\n",
        "\n",
        "        # Function to train the GAN, where you alternate between the training of the genenator and discriminator\n",
        "#--------------------------------------------------------------------------------------------------------\n",
        "\n",
        "    def train(self):\n",
        "\n",
        "       # Setting empty arrays for storing the losses\n",
        "\n",
        "        Ninner = 1\n",
        "        self.train_hist = {}\n",
        "        self.train_hist['D_loss'] = []\n",
        "        self.train_hist['G_loss'] = []\n",
        "\n",
        "        # Setting up the labels for real and fake images\n",
        "        #self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1).cuda(), torch.zeros(self.batch_size, 1).cuda()\n",
        "        self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1).fill_(0.9).type(torch.float32).cuda(), torch.zeros(self.batch_size, 1).fill_(0.1).type(torch.float32).cuda()\n",
        "        print(self.y_real_.shape)\n",
        "        self.y_real_ = self.y_real_ + (torch.randn(self.y_real_.shape)*0.03).cuda()\n",
        "        self.y_fake_ = self.y_fake_ + (torch.randn(self.y_fake_.shape)*0.03).cuda()\n",
        "\n",
        "        print('training start!!')\n",
        "\n",
        "        randn_var = 0.05\n",
        "        randn_mean = 0.00\n",
        "\n",
        "        # Epoch loops\n",
        "\n",
        "        for epoch in range(self.epoch):\n",
        "            epoch_start_time = time.time()\n",
        "            print(\"Epoch:\", epoch+1)\n",
        "\n",
        "            for iter, (x_, _) in enumerate(self.data_loader):\n",
        "                if iter == self.data_loader.dataset.__len__() // self.batch_size:\n",
        "                    break\n",
        "\n",
        "                # Generate random noise to push through the generator   \n",
        "\n",
        "                z_ = torch.rand((self.batch_size, self.z_dim))\n",
        "                x_, z_ = x_.cuda(), z_.cuda()\n",
        "\n",
        "                # YOUR CODE HERE\n",
        "                #--------------------\n",
        "\n",
        "                # update D network using \n",
        "                # 1. Set optimizer gradient to zero\n",
        "                self.D_optimizer.zero_grad()\n",
        "                # 2. Set discriminator losses on real and fake data\n",
        "                x_ = x_ + torch.normal(mean=randn_mean, std=randn_var, size=x_.shape).cuda()\n",
        "                #x_ = x_ + (torch.randn(x_.shape)*randn_var + randn_mean).cuda() # Adding random noise to input images\n",
        "                D_real = self.D(x_)\n",
        "                D_real_loss = self.BCE_loss(D_real, self.y_real_)\n",
        "\n",
        "                z_ = z_ + torch.normal(mean=randn_mean, std=randn_var, size=z_.shape).cuda()\n",
        "\n",
        "                G_ = self.G(z_)\n",
        "                D_fake = self.D(G_)\n",
        "                D_fake_loss = self.BCE_loss(D_fake, self.y_fake_)\n",
        "                # 3. Do back propagation to compute gradients\n",
        "                D_loss = D_real_loss + D_fake_loss\n",
        "                D_loss.backward()\n",
        "\n",
        "                if iter == 0:\n",
        "                    print(\"D eigen vectors:\")\n",
        "                    get_eigenvectors(self.D, self.data_loader)\n",
        "\n",
        "\n",
        "                # 4. Make a step of D_optimizer\n",
        "                self.D_optimizer.step()\n",
        "                # 5. Set the current loss in self.train_hist['D_loss]\n",
        "                self.train_hist['D_loss'].append(D_loss.item())\n",
        "                \n",
        "                # update G network using \n",
        "                # 1. Set optimizer gradient to zero\n",
        "                self.G_optimizer.zero_grad()\n",
        "                # 2. Set generator losses on fake data\n",
        "                G_ = self.G(z_)\n",
        "                D_fake_ = self.D(G_)\n",
        "                G_loss = self.BCE_loss(D_fake_, self.y_real_)\n",
        "                # 3. Do back propagation to compute gradients\n",
        "                G_loss.backward()\n",
        "\n",
        "                if iter == 0:\n",
        "                    print(\"G eigen vectors:\")\n",
        "                    get_eigenvectors(self.G, self.data_loader)\n",
        "                    \n",
        "                # 4. Make a step of G_optimizer\n",
        "                self.G_optimizer.step()\n",
        "                # 5. Set the current loss in self.train_hist['G_loss]    \n",
        "                self.train_hist['G_loss'].append(G_loss.item())\n",
        "\n",
        "                # Print iterations and losses\n",
        "                \n",
        "                if ((iter + 1) % 50) == 0:\n",
        "                  print(\"Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f\" %\n",
        "                          ((epoch + 1), (iter + 1), self.data_loader.dataset.__len__() // self.batch_size, D_loss.item(), G_loss.item()))\n",
        "                \n",
        "            # Visualize results\n",
        "            #if ((epoch + 1) % 10) == 0:\n",
        "            with torch.no_grad():\n",
        "                visualize_results(self)\n",
        "                #visualize_gan_optim_loss(self)\n",
        "\n",
        "        print(\"Training finished!\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlpS9IeX5Kac"
      },
      "source": [
        "# Training the GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "xKeKUuUR5JuM",
        "outputId": "0ccd5dd4-d5f0-4ea7-af76-8145f83614a7"
      },
      "source": [
        "params = {'beta1': 0.5, 'beta2': 0.999,'lr_g':0.0002,'lr_d':0.0002,'max_epochs':1}\n",
        "params['z_dim'] = 16\n",
        "params['base_size'] = 64\n",
        "\n",
        "gan = GAN(params)\n",
        "gan.train()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([300, 1])\n",
            "training start!!\n",
            "Epoch: 1\n",
            "D eigen vectors:\n",
            "52865\n",
            "Hessian vector shape: torch.Size([52865])\n",
            "n: 40\n",
            "input: torch.Size([300, 1, 28, 28])\n",
            "target: torch.Size([300, 1, 28, 28])\n",
            "output: torch.Size([300, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-31b2fa4f4626>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-d98f3f52cda8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"D eigen vectors:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                     \u001b[0mget_eigenvectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-cdc01a8a8d93>\u001b[0m in \u001b[0;36mget_eigenvectors\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#A = linalg.LinearOperator(shape=(num_params, num_params), matvec=lambda v: hv.calculate(v))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearOperator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatvec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/linalg/interface.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, shape, matvec, rmatvec, matmat, dtype, rmatmat)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__matmat_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_matmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/linalg/interface.py\u001b[0m in \u001b[0;36m_init_dtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_matmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/linalg/interface.py\u001b[0m in \u001b[0;36mmatvec\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1 into shape (52865,)"
          ]
        }
      ]
    }
  ]
}